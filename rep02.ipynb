{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prática"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiplicação de matrizes\n",
    "\n",
    "Duas funções úteis em python para trabalhar com matrizes são:\n",
    "\n",
    "- `np.eye`: retorna uma matriz identidade\n",
    "- `np.ones`: retorna um vetor de 1s\n",
    "\n",
    "Pesquise na Internet e help() sobre as funções."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício\n",
    "\n",
    "O código abaixo é uma forma tradicional de implementar uma média ponderada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Dados de entrada\n",
    "values = np.array([1, 2, 3, 4, 5])\n",
    "weights = np.array([0.1, 0.2, 0.3, 0.2, 0.2])\n",
    "\n",
    "# Solução com laços\n",
    "weighted_sum_loop = 0\n",
    "sum_weights = 0\n",
    "for i in range(len(values)):\n",
    "    weighted_sum_loop += values[i] * weights[i]\n",
    "    sum_weights += weights[i]\n",
    "weighted_average_loop = weighted_sum_loop / sum_weights\n",
    "weighted_average_loop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça uma versão do código acima utilizando apenas álgebra matricial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solução com multiplicação de matrizes\n",
    "weighted_average_matrix = (values @ weights) / (weights @ np.ones(len(weights)))\n",
    "weighted_average_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Versão ao estilo python\n",
    "weighted_average_func = np.sum(values * weights) / np.sum(weights)\n",
    "weighted_average_func"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício\n",
    "\n",
    "Estude o código abaixo para compreender as operações realizadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado: 279.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Dados de entrada\n",
    "X = np.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]])\n",
    "\n",
    "# O trecho abaixo realiza a média do quadrado da soma das linhas, ou seja:\n",
    "# 1 - primeiro, soma-se os elementos de cada linha, resultando em 1 soma por linha (3 elementos)\n",
    "# 2 - depois, cada elemento é elevado ao quadrado\n",
    "# 3 - por fim, tira-se a média dos valores\n",
    "result = 0\n",
    "for row in X:\n",
    "    row_sum = 0\n",
    "    for element in row:\n",
    "        row_sum += element\n",
    "    row_squared = row_sum ** 2\n",
    "    result += row_squared\n",
    "result /= X.shape[0]\n",
    "\n",
    "print(\"Resultado:\", result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora escreva uma versão do mesmo código, mas utilizando apenas a operação de multiplicação de matrizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279.0\n"
     ]
    }
   ],
   "source": [
    "# Preencha as partes faltantes\n",
    "row_sums = X @ np.ones(len(X)) # Soma das linhas\n",
    "result = (row_sums @ row_sums) / X.shape[0] # eleve cada elemento ao quadrado e calcule a médi\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado: 279.0\n"
     ]
    }
   ],
   "source": [
    "# Versão ao estilo python (composição de funções sobre dados imutáveis)\n",
    "#\n",
    "# Novas linguagens incorporam o estilo de programação funcional, com diversas funções que simplificam a escrita e código. Vale a pena as estudar\n",
    "result = (X.sum(axis=1) ** 2).mean()\n",
    "\n",
    "print(\"Resultado:\", result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding vectors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similaridade de cosseno e distância euclidiana\n",
    "\n",
    "Implemente as seguintes funções para analisar similaridade entre vetores: similaridade de cosseno e distância euclidiana"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distância euclidiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vec1, vec2):    \n",
    "    diff = vec1 - vec2\n",
    "    quad_diff = diff * diff\n",
    "    sum_quad = quad_diff @ np.ones(len(quad_diff))\n",
    "    distancia = np.sqrt(sum_quad)\n",
    "    # print(vec1)\n",
    "    # print(vec2)\n",
    "    # print(diff)\n",
    "    # print(quad_diff)\n",
    "    # print(sum_quad)\n",
    "    # print(distancia)\n",
    "    return distancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testa a função\n",
    "arrays = np.array(([3, 0], [1, 3]))\n",
    "assert euclidean_distance( *arrays ) == 13**0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similaridade de cosseno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    return (vec1 @ vec2) / (np.sqrt(vec1 @ vec1) * np.sqrt(vec2 @ vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testa a função\n",
    "arrays = np.array(([2, 4, 6], [1, 2, 3]))\n",
    "assert cosine_similarity( *arrays ) == 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Transformer\n",
    "\n",
    "No exercício abaixo, utilize o modelo [paraphrase-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L6-v2). Este é um modelo muito eficiente para comparação de sentenças, pequeno e veloz. Veja uma [comparação](https://www.sbert.net/docs/pretrained_models.html) entre alguns modelos.\n",
    "\n",
    "Sua tarefa é encontrar quais sentenças são mais semelhantes entre si.\n",
    "\n",
    "Primeiro carregue o modelo indicado abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilize as seguintes sentenças\n",
    "sentences = [\n",
    "    \"My mom\",\n",
    "    \"I went to the market to buy fish\",\n",
    "    \"I went to the market to buy salmon and tomato\",\n",
    "    \"I went to the market to buy tomato and deodorant\",\n",
    "    \"I went to the market to buy candies\",\n",
    "    \"Poop\",\n",
    "    \"I love chocolate\",\n",
    "    \"Vegetables\",\n",
    "    \"Don't forget your sweater\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 384)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retorna uma lista de embedding vectors, cada um correspondendo a uma das sentenças\n",
    "sentence_embeddings = model.encode(sentences)\n",
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza sua função criada `cosine_similarity` para calcular a similaridade entre os vetores\n",
    "def similarity_between_lists(list1, list2):\n",
    "    return np.array([[cosine_similarity(vec1, vec2) for vec2 in list2] for vec1 in list1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.255914</td>\n",
       "      <td>0.244027</td>\n",
       "      <td>0.229939</td>\n",
       "      <td>0.242855</td>\n",
       "      <td>0.124054</td>\n",
       "      <td>0.199148</td>\n",
       "      <td>0.167029</td>\n",
       "      <td>0.278760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.255914</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864093</td>\n",
       "      <td>0.671755</td>\n",
       "      <td>0.690502</td>\n",
       "      <td>0.125447</td>\n",
       "      <td>0.183078</td>\n",
       "      <td>0.268821</td>\n",
       "      <td>0.101010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.244027</td>\n",
       "      <td>0.864093</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.759449</td>\n",
       "      <td>0.614653</td>\n",
       "      <td>0.128634</td>\n",
       "      <td>0.153153</td>\n",
       "      <td>0.389119</td>\n",
       "      <td>0.180666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.229939</td>\n",
       "      <td>0.671755</td>\n",
       "      <td>0.759449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625138</td>\n",
       "      <td>0.225643</td>\n",
       "      <td>0.022885</td>\n",
       "      <td>0.361932</td>\n",
       "      <td>0.260928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.242855</td>\n",
       "      <td>0.690502</td>\n",
       "      <td>0.614653</td>\n",
       "      <td>0.625138</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.105269</td>\n",
       "      <td>0.263978</td>\n",
       "      <td>0.277746</td>\n",
       "      <td>0.100283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.124054</td>\n",
       "      <td>0.125447</td>\n",
       "      <td>0.128634</td>\n",
       "      <td>0.225643</td>\n",
       "      <td>0.105269</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.095049</td>\n",
       "      <td>0.175825</td>\n",
       "      <td>0.127986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.199148</td>\n",
       "      <td>0.183078</td>\n",
       "      <td>0.153153</td>\n",
       "      <td>0.022885</td>\n",
       "      <td>0.263978</td>\n",
       "      <td>0.095049</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038808</td>\n",
       "      <td>0.134812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.167029</td>\n",
       "      <td>0.268821</td>\n",
       "      <td>0.389119</td>\n",
       "      <td>0.361932</td>\n",
       "      <td>0.277746</td>\n",
       "      <td>0.175825</td>\n",
       "      <td>0.038808</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.091382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.278760</td>\n",
       "      <td>0.101010</td>\n",
       "      <td>0.180666</td>\n",
       "      <td>0.260928</td>\n",
       "      <td>0.100283</td>\n",
       "      <td>0.127986</td>\n",
       "      <td>0.134812</td>\n",
       "      <td>0.091382</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \n",
       "0  1.000000  0.255914  0.244027  0.229939  0.242855  0.124054  0.199148  \\\n",
       "1  0.255914  1.000000  0.864093  0.671755  0.690502  0.125447  0.183078   \n",
       "2  0.244027  0.864093  1.000000  0.759449  0.614653  0.128634  0.153153   \n",
       "3  0.229939  0.671755  0.759449  1.000000  0.625138  0.225643  0.022885   \n",
       "4  0.242855  0.690502  0.614653  0.625138  1.000000  0.105269  0.263978   \n",
       "5  0.124054  0.125447  0.128634  0.225643  0.105269  1.000000  0.095049   \n",
       "6  0.199148  0.183078  0.153153  0.022885  0.263978  0.095049  1.000000   \n",
       "7  0.167029  0.268821  0.389119  0.361932  0.277746  0.175825  0.038808   \n",
       "8  0.278760  0.101010  0.180666  0.260928  0.100283  0.127986  0.134812   \n",
       "\n",
       "          7         8  \n",
       "0  0.167029  0.278760  \n",
       "1  0.268821  0.101010  \n",
       "2  0.389119  0.180666  \n",
       "3  0.361932  0.260928  \n",
       "4  0.277746  0.100283  \n",
       "5  0.175825  0.127986  \n",
       "6  0.038808  0.134812  \n",
       "7  1.000000  0.091382  \n",
       "8  0.091382  1.000000  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifique a similaridade entre as frases\n",
    "distances = pd.DataFrame( similarity_between_lists(sentence_embeddings[:], sentence_embeddings[:]) ) # sklearn possui a função: cosine_similarity(sentence_embeddings)\n",
    "distances"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora liste quais pares de frases distintas são as mais próximas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('My mom', \"Don't forget your sweater\"),\n",
       " ('I went to the market to buy fish',\n",
       "  'I went to the market to buy salmon and tomato'),\n",
       " ('I went to the market to buy salmon and tomato',\n",
       "  'I went to the market to buy fish'),\n",
       " ('I went to the market to buy tomato and deodorant',\n",
       "  'I went to the market to buy salmon and tomato'),\n",
       " ('I went to the market to buy candies', 'I went to the market to buy fish'),\n",
       " ('Poop', 'I went to the market to buy tomato and deodorant'),\n",
       " ('I love chocolate', 'I went to the market to buy candies'),\n",
       " ('Vegetables', 'I went to the market to buy salmon and tomato'),\n",
       " (\"Don't forget your sweater\", 'My mom')]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crie uma matrix identidade da ordem de \"distances\"\n",
    "num_rows, num_cols = distances.shape\n",
    "order = min(num_rows, num_cols)\n",
    "eye_matrix = np.eye(order)\n",
    "\n",
    "# retorna as combinações mais próximas\n",
    "[(sentences[idx], sentences[near]) for idx, near in\n",
    "    (distances - eye_matrix).idxmax().items()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analise a capacidade do modelo em relacionar a semântica das frases. Para cada frase, analise a correspondente mais próxima.\n",
    "\n",
    "Resultado:\n",
    "\n",
    "1. Ao associar a palavra `fish` com `salmon`\n",
    "1. Ao associar a palavra `poop` com `deodorant`\n",
    "1. Ao associar a relação de `amar chocolate` e então ir ao mercado `comprar doces`\n",
    "1. Ao associar a palavra `vegetables` com `tomato`\n",
    "1. Ao associar a palavra `mom` com frases comum das mães\n",
    "\n",
    "Qual é a segunda frase que mais se aproxima de `my mom`? Sabe explicar o motivo?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Com toda certeza ele conseguiu correlacionar bem peixe com salmão, já que para ambos os casos de comparar A com B o maior resultado foi sempre nos pares fish/salmon."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Se for analisar, não existe nada muito próximo de poop, porém ele conseguiu correlacionar na melhor das hipóteses desodorante. E está até que coerente, já que as duas coisas podem ser encontradas no mesmo ambiente, o banheiro."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Essa capacidade de relacionar fortemente amar chocolate com comprar doces incrivelmente não foi recíproca, uma vez que comprar doces ficou com uma relação mais forte com ir ao mercado comprar doce. Mas de qualquer forma, a capacidade de relacionar está altíssima."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Novamente, ele conseguiu relacionar bem tomate com vegetais, conseguindo relacionar um item com um grupo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Essa última associação foi muito interessante, já que ele conseguiu associar pessoas com frases que possivelmente essas pessoas falariam. Uma vez que é de senso comum, e se repete muito na literatura que mães alertam os filhos sobre pegarem casacos para sair de casa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
